## 1. AOF Rewrite 分析

### 1.1 AOF介绍

Redis提供两种持久化机制

1. RDB: 将数据库的快照以二进制的方式保存到磁盘；
2. AOF: 将所有写入命令及相关参数以协议文本的方式写入文件并持久保存磁盘。

本文只关心AOF，简单介绍一下：Redis Server将所有写入的命令转换成协议文本的方式写入AOF文件，例如：Server收到 set key value的的写入命令，server会进行以下几步操作：

1. 将命令转换成协议文本，转换后的结果：`*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n`；
2. 将协议文本追加到aof缓存，也就是aof_buf；
3. 根据sync策略调用fsync/fdatasync。

到目前为止已经成功保存数据，如果想要还原AOF，只需要将AOF里命令读出来并重放就可以还原数据库。

AOF持久化机制存在一个致命的问题，随着时间推移，AOF文件会膨胀，如果频繁写入AOF文件会膨胀到无限大，当server重启时严重影响数据库还原时间，影响系统可用性。为解决此问题，系统需要定期重写AOF文件，目前采用的方式是创建一个新的AOF文件，将数据库里的全部数据转换成协议的方式保存到文件中，通过此操作达到减少AOF文件大小的目的，重写后的大小一定是小于等于旧AOF文件的大小。

重写AOF提供两种方式

1. REWRITE: 在主线程中重写AOF，会阻塞工作线程，在生产环境中很少使用，处于废弃状态；
2. BGREWRITE: 在后台（子进程）重写AOF, 不会阻塞工作线程，能正常服务，此方法最常用。

本文只关心BGREWRITE的问题，因此只介绍此命令的实现机制。

### 1.2 AOF后台Rewrite实现方式

Server收到BGREWRITE命令或者系统触发AOF重写时，主进创建一个子进程并进行AOF重写，主进程异步等待子进程结束（信号量），此时主进程能正常接收处理用户请求，用户请求会修改数据库里数据，会使得当前数据库的数据跟重写后AOF里不一致，需要有种机制保证数据的一致性。当前的做法是在重写 AOF 期间系统会新开一块内存用于缓存重写期间收到的命令，在重写完成以后再将缓存中的数据追加到新的AOF。在处理命令时既要将命令追加到 aof_buf，也要追加到重写AOF Buffer。

### 1.3 AOF后台Rewrite存在的问题

重写AOF Buffer是个不限大小的buffer,但用户写入的数据量较多时会出现以下两个问题：

1. 占用过多内存，浪费资源；
2. 主进程将AOF buffer数据写入到新AOF文件中时会阻塞工作线程，用户正常请求的延时会变高，严重情况下会超时，主备同步也会出问题，断开重连，重新同步等。

### 1.4 AOF后台Rewrite解决方案

#### 1.4.1 官方解决方案

主要思路是AOF重写期间，主进程跟子进程通过管道通信，主进程实时将新写入的数据发送给子进程，子进程从管道读出数据交缓存在buffer中，子进程等待存量数据全部写入AOF文件后，将缓存数据追加到AOF文件中，此方案只是解决阻塞工作线程问题，但占用内存过多问题并没有解决。

#### 1.4.2 新解决方案

主要思路是AOF重写期间，主进程创建一个新的aof_buf，新的AOF文件用于接收新写入的命令，sync策略保持不变，在AOF重写期间，系统需要向两个aof_buf，两个AOF文件同时追加新写入的命令。当主进程收到子进程重写AOF文件完成后，停止向老的aof_buf，AOF文件追加命令，然后删除旧的AOF文件(流程跟原来保持一致)；将将子进程新生成的AOF文件重命名为appendonly.aof.last，具体流程如下：

1. 停止向旧的aof_buf，AOF文件追加命令；
2. 删除旧的的appendonly.aof.last文件；
3. 交换两个aof_buf，AOF文件指针；
4. 回收旧的aof_buf，AOF文件；
5. 重命令子进程生成的AOF文件为appendonly.aof.last；

系统运行期间同时存在两个AOF文件，一个是当前正在写的AOF，另一个是存量的AOF数据文件。因此需要修改数据库恢复相关逻辑，加载AOF时先要加载存量数据appendonly.aof.last,再加载appendonly.aof。

### 参考

[Redis · 特性分析 · AOF Rewrite 分析](http://mysql.taobao.org/monthly/2016/03/05/)



## 2. 热点 Key 问题解决方案

### 2.1 背景

在分布式K-V存储系统中，对某个key进行读写时，会根据该key的hash计算出一台固定的server来存取该K-V，如果集群不发生服务器数量变化，那么这一映射关系就不会变化。

云数据库 memcached 就是这样一种K-V缓存系统。在实际应用中的某些高峰时段，有的云数据库 memcached 用户会大量请求同一个Key（可能对应应用的热卖商品、热点新闻、热点评论等），所有的请求（且这类请求读写比例非常高）都会落到同一个server上，该机器的负载就会严重加剧，此时整个系统增加新server也没有任何用处，因为根据hash算法，同一个key的请求还是会落到同一台新机器上，该机器依然会成为系统瓶颈。这个问题称为“热点key”问题。

### 2.2 现状

用户使用云数据库 memcached 就是为了提升业务性能，难免会触发“热点key问题”。但云数据库memcached做为公有云服务，在发现有热点的情况下，如果继续放任该热点无限激增，就会带来整个系统雪崩。所以当前的做法是对每个用户在每台服务器上分配一定的QPS或带宽，当用户在某台服务器上的请求超过该用户的配额，我们就会对用户进行流控，服务端返回TEMPORARY_FAILURE，该限制会影响用户正常请求，持续时间分钟级。

### 2.3 思考

用户触发热点问题是业务需要，是理所当然；云数据库 memcached 对热点 key 进行流控是保障系统稳定性，也在情理之中。但有没有一种既能提供用户热点 key 访问的需求，又能保护云数据库memcached服务器的方法呢，这正是本文所要阐述的。

解决热点问题有很多办法，比如**用户如果提前知道某些key可能成为热点，那么客户端可以提前拆分热点key**；也可以**搭建一个备用集群，写的时候双写，然后随机双读**。这些方案的实现前提和难度可想而知，下面给出的是对应用透明，且动态发现热点的解决方案。

### 2.4 解决方案

#### 2.4.1 整体思路

本方案解决的是用户读热点问题，不解决写热点问题。

首先，云数据库memcached简单架构图如下：

![memcache simple architechture](http://blog-1259650185.cosbj.myqcloud.com/img/202203/30/1648606893.png)

我们的proxy是无状态层，上面做了些访问控制功能，用户客户端到proxy是随机的，不受固定算法（如hash）控制。而proxy到DataServer的链路是根据key决定的，当用户访问热点key时，所有proxy上关于该key的请求都会落到同一台DataServer。

**所以解决热点问题，其核心思路是：每台DataServer对所有key进行采样、定位，实时计算出当前热点key，将其反馈给proxy层，由proxy缓存备份。即负载压力由DataServer转向proxy。理由是：Proxy可以无状态扩容，而DataServer不可以。**

#### 2.4.2 DataServer如何发现热点

每台服务器有个HotKey逻辑，让每个到达服务器的目标请求（可配置不同类型请求）经历三个流水阶段：

1. 采样阶段（根据配置设定采样次数sample_max） 本阶段输出：是否有热点现象，如果有热点，输出热点的桶号供下阶段使用。
2. 定位阶段（根据配置设定采样次数reap_max） 本阶段输出：热点key（如果满足阈值），并添加到服务端的LRU链表。
3. 反馈阶段 对到达服务器的目标请求，取出key，然后查询LRU链表判断该key是否为热点key。如果是热点，就会在请求结束后，向proxy发送一个feedback包，通知proxy。

至此，服务器hot-key逻辑结束。流程图如下：

<img src="http://blog-1259650185.cosbj.myqcloud.com/img/202203/30/1648607361.png" alt="HotKey逻辑流程" style="zoom:50%;" />

#### 2.4.3 发现热点后proxy怎么处理

当Proxy收到DataServer的热点反馈之后，会将该key写入到自己的LRU-cache里面，该cache的过期时间和容量大小都交由用户通过控制台设置，默认分别是100ms和30。这样热点的key就已经存在于与proxy中了，下次用户请求就可以直接返回了。

#### 2.4.4 如何保证数据一致性呢？

下面讨论都是用户client已经触发了热点key问题，假设用户client跟每个proxy都建立了链接，并且每个proxy上都有对热点key的请求，那么理论上每个proxy的LRU-cache都有一份数据。

**我们保证单条连接上的一致性。** 当用户client和proxy1建立连接，用户修改了一个key（任何写操作），proxy1上会在LRU-cache中同步删除该key，新key就会写到DataServer上，然后在读数据的时候，由于LRU-cache不命中，就会从DataServer上拿到最新数据。

**不同链接上只能提供弱一致性。** 如果这个时候用户从proxy2上读热点数据呢？理论上就会读到老数据，该数据将于100ms之后从proxy-cache中过期淘汰掉，之后就会更新会最新数据，即不同连接间可能有100ms不一致。

**怎样看待弱一致性。** 事实上，不开启热点key功能，在不同链接上也会存在弱一致。假设用户client建立了两条链接到云数据库memcached，在链接1上写入key-value1，在链接1、2上分别读该key。当链接1上用户update了key-value2，这个请求需要一定的网络延迟才能写入到服务端，如果这个时候链接2上同时发起对key的读取操作，如果读请求先到服务端，它将读到的是value1的老值。

所以开启热点key功能，只是增加了不一致时间，且该功能为可选，控制权由用户掌握。

#### 2.4.5 适用场景

由以上分析可以看到，开启热点key功能之后，只会对用户的读请求产生影响，该影响增加了不同链接上的弱一致性的时间。因此，该功能适合读多写少，且对强一致性要求不高的应用。

#### 2.4.6 收益

整个方案核心是负载压力由DataServer转移到Proxy。好处如下：

1. 因为DataServer扩容也解决不了热点问题，而Proxy可以无状态扩容，对用户来讲就极大提升了热点key访问的能力，不受单点制约；
2. 缩短了服务端处理链路，对用户平均RT也所降低；
3. 免除服务端热点流控的分钟级别影响。

### 参考

[Memcached · 最佳实践 · 热点 Key 问题解决方案](http://mysql.taobao.org/monthly/2016/04/06/)

















